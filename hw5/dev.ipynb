{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load reader.py\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "import skimage.transform\n",
    "import csv\n",
    "import collections\n",
    "import os\n",
    "\n",
    "def readShortVideo(video_path, video_category, video_name, downsample_factor=12, rescale_factor=1):\n",
    "    '''\n",
    "    @param video_path: video directory\n",
    "    @param video_category: video category (see csv files)\n",
    "    @param video_name: video name (unique, see csv files)\n",
    "    @param downsample_factor: number of frames between each sampled frame (e.g., downsample_factor = 12 equals 2fps)\n",
    "    @param rescale_factor: float of scale factor (rescale the image if you want to reduce computations)\n",
    "\n",
    "    @return: (T, H, W, 3) ndarray, T indicates total sampled frames, H and W is heights and widths\n",
    "    '''\n",
    "\n",
    "    filepath = video_path + '/' + video_category\n",
    "    filename = [file for file in os.listdir(filepath) if file.startswith(video_name)]\n",
    "    video = os.path.join(filepath,filename[0])\n",
    "\n",
    "    videogen = skvideo.io.vreader(video)\n",
    "    frames = []\n",
    "    for frameIdx, frame in enumerate(videogen):\n",
    "        if frameIdx % downsample_factor == 0:\n",
    "            frame = skimage.transform.rescale(frame, rescale_factor, mode='constant', preserve_range=True).astype(np.uint8)\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return np.array(frames).astype(np.uint8)\n",
    "\n",
    "\n",
    "def getVideoList(data_path):\n",
    "    '''\n",
    "    @param data_path: ground-truth file path (csv files)\n",
    "\n",
    "    @return: ordered dictionary of videos and labels {'Action_labels', 'Nouns', 'End_times', 'Start_times', 'Video_category', 'Video_index', 'Video_name'}\n",
    "    '''\n",
    "    result = {}\n",
    "\n",
    "    with open (data_path) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            for column, value in row.items():\n",
    "                result.setdefault(column,[]).append(value)\n",
    "\n",
    "    od = collections.OrderedDict(sorted(result.items()))\n",
    "    return od\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class Extractor:\n",
    "    def __init__(self, shape=(224, 224, 3)):\n",
    "        # input information\n",
    "        self.H, self.W, self.C = shape\n",
    "\n",
    "        # parameter dictionary\n",
    "        self.para_dict = dict()\n",
    "        \n",
    "    def build(self, vgg16_npy_path):\n",
    "        \"\"\"\n",
    "        load pre-trained weights from path\n",
    "        :param vgg16_npy_path: file path of vgg16 pre-trained weights\n",
    "        \"\"\"\n",
    "\n",
    "        # input placeholder\n",
    "        rgb_input = tf.placeholder(tf.float32, [None, self.H, self.W, self.C])\n",
    "        self.is_train = tf.placeholder(tf.bool)\n",
    "        \n",
    "        # Convert RGB to BGR\n",
    "        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_input)\n",
    "        self.x = tf.concat(axis=3,\n",
    "                           values=[blue - 103.939,\n",
    "                                   green - 116.779,\n",
    "                                   red - 123.68,])\n",
    "        \n",
    "        assert self.x.get_shape().as_list()[1:] == [self.H, self.W, self.C]\n",
    "\n",
    "        # load pre-trained weights\n",
    "        if isinstance(vgg16_npy_path,dict):\n",
    "            self.data_dict = vgg16_npy_path\n",
    "            print(\"parameters loaded\")\n",
    "        else:\n",
    "            self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "            print(\"npy file loaded\")\n",
    "\n",
    "        ### pre-trained VGG-16 start ###\n",
    "        conv1_1 = self.conv_layer( self.x, \"conv1_1\")\n",
    "        conv1_2 = self.conv_layer(conv1_1, \"conv1_2\")\n",
    "        pool1 = self.max_pool_layer(conv1_2, \"pool1\")\n",
    "\n",
    "        conv2_1 = self.conv_layer(  pool1, \"conv2_1\")\n",
    "        conv2_2 = self.conv_layer(conv2_1, \"conv2_2\")\n",
    "        pool2 = self.max_pool_layer(conv2_2, \"pool2\")\n",
    "\n",
    "        conv3_1 = self.conv_layer(  pool2, \"conv3_1\")\n",
    "        conv3_2 = self.conv_layer(conv3_1, \"conv3_2\")\n",
    "        conv3_3 = self.conv_layer(conv3_2, \"conv3_3\")\n",
    "        pool3 = self.max_pool_layer(conv3_3, \"pool3\")\n",
    "\n",
    "        conv4_1 = self.conv_layer(  pool3, \"conv4_1\")\n",
    "        conv4_2 = self.conv_layer(conv4_1, \"conv4_2\")\n",
    "        conv4_3 = self.conv_layer(conv4_2, \"conv4_3\")\n",
    "        pool4   = self.max_pool_layer(conv4_3, \"pool4\")\n",
    "\n",
    "        conv5_1 = self.conv_layer(  pool4, \"conv5_1\")\n",
    "        conv5_2 = self.conv_layer(conv5_1, \"conv5_2\")\n",
    "        conv5_3 = self.conv_layer(conv5_2, \"conv5_3\")\n",
    "        pool5 = self.max_pool_layer(conv5_3, \"pool5\")\n",
    "        # flatten = tf.reduce_mean(conv5_3, [1,2])\n",
    "        ### pre-trained VGG-16 end ###\n",
    "        \n",
    "        flatten = self.flatten_layer(pool5)\n",
    "        self.output = flatten\n",
    "        \n",
    "    def avg_pool_layer(self, bottom, name):\n",
    "        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def max_pool_layer(self, bottom, name):\n",
    "        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def dropout_layer(self, bottom, keep_prob):\n",
    "        if self.is_train == True:\n",
    "            return tf.nn.dropout(bottom, keep_prob=keep_prob)\n",
    "        else:\n",
    "            return bottom\n",
    "\n",
    "    def trans_conv_layer(self, bottom, output_shape, stride, name=None, shape=None):\n",
    "        with tf.variable_scope(\"VGG16\", reuse=tf.AUTO_REUSE):\n",
    "            if shape is not None:\n",
    "                conv_filter = self.get_conv_filter(shape=shape, name=name, with_bn=False)\n",
    "                conv_bias = self.get_bias(shape=shape[2], name=name)\n",
    "            elif name in self.data_dict.keys():\n",
    "                conv_filter = self.get_conv_filter(name=name, with_bn=False)\n",
    "                conv_bias = self.get_bias(name=name)\n",
    "            else:\n",
    "                print(\"Neither give a shape nor lack a pre-trained layer called %s\" % name)\n",
    "        \n",
    "        self.para_dict[name] = [conv_filter, conv_bias]\n",
    "\n",
    "        conv = tf.nn.conv2d_transpose(bottom, conv_filter, output_shape, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "        conv = tf.nn.bias_add(conv, conv_bias)\n",
    "\n",
    "        return conv\n",
    "\n",
    "    def conv_layer(self, bottom, name=None, shape=None):\n",
    "        with tf.variable_scope(\"VGG16\",reuse=tf.AUTO_REUSE):\n",
    "            if name in self.data_dict.keys():\n",
    "                conv_filter = self.get_conv_filter(name=name)\n",
    "                conv_bias = self.get_bias(name=name)\n",
    "            else:\n",
    "                print(\"Neither give a shape nor lack a pre-trained layer called %s\" % name)\n",
    "        \n",
    "        self.para_dict[name] = [conv_filter, conv_bias]\n",
    "        \n",
    "        conv = tf.nn.conv2d(bottom, conv_filter, [1, 1, 1, 1], padding='SAME')\n",
    "        conv = tf.nn.bias_add(conv, conv_bias)\n",
    "        relu = tf.nn.relu(conv)\n",
    "        return relu\n",
    "    \n",
    "    def flatten_layer(self, bottom):\n",
    "        shape = bottom.get_shape().as_list()\n",
    "        dim = 1\n",
    "        for d in shape[1:]:\n",
    "            dim *= d\n",
    "        x = tf.reshape(bottom, [-1, dim])\n",
    "        return x\n",
    "    \n",
    "    def dense_layer(self, bottom, name=None):\n",
    "        with tf.variable_scope(\"VGG16\",reuse=True):\n",
    "            weights = tf.get_fc_weight(name=name+\"_W\")\n",
    "            biases = tf.get_bias(name=name+\"_b\")\n",
    "\n",
    "        # Fully connected layer. Note that the '+' operation automatically broadcasts the biases.\n",
    "        fc = tf.nn.bias_add(tf.matmul(bottom, weights), biases)\n",
    "        return fc\n",
    "        \n",
    "    def get_conv_filter(self, shape=None, name=None, with_bn=True):\n",
    "        if shape is not None:\n",
    "            conv_filter = tf.get_variable(shape=shape, initializer=tf.truncated_normal_initializer(mean=0, stddev=0.1), name=name+\"_W\", dtype=tf.float32)\n",
    "            return conv_filter\n",
    "        elif name in self.data_dict.keys():\n",
    "            conv_filter = tf.get_variable(initializer=self.data_dict[name][0], name=name+\"_W\")\n",
    "            return conv_filter\n",
    "        else:\n",
    "            print(\"Neither give a shape nor lack a pre-trained layer called %s\" % name)\n",
    "            return None\n",
    "            \n",
    "    def get_bias(self, name=None, shape=None):\n",
    "        if shape is not None:\n",
    "            return tf.get_variable(shape=shape, initializer=tf.truncated_normal_initializer(mean=0, stddev=0.1), name=name+\"_b\", dtype=tf.float32)\n",
    "        elif name in self.data_dict.keys(): \n",
    "            return tf.get_variable(initializer=self.data_dict[name][1], name=name+\"_b\")\n",
    "        else:\n",
    "            print(\"(get_bias) neither give a shape nor lack a pre-trained layer called %s\" % name)\n",
    "            return None\n",
    "        \n",
    "    def get_fc_weight(self, name, shape=None):\n",
    "        if shape is not None:\n",
    "            return tf.get_variable(shape=shape, initializer=tf.truncated_normal_initializer(mean=0, stddev=0.1), name=name+\"_W\", dtype=tf.float32)\n",
    "        elif name in self.data_dict.keys():\n",
    "            return tf.get_variable(initializer=self.data_dict[name][0], name=name+\"_W\")\n",
    "        else:\n",
    "            print(\"(get weight) neither give a shape nor lack a pre-trained layer called %s\" % name)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(arr, num_classes):\n",
    "    res = np.zeros((arr.size, num_classes))\n",
    "    res[np.arange(arr.size),arr] = 1\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"HW5_data/TrimmedVideos/video/\"\n",
    "train_video_path = video_path + \"train/\"\n",
    "valid_video_path = video_path + \"valid/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = getVideoList(\"HW5_data/TrimmedVideos/label/gt_train.csv\")\n",
    "valid_list = getVideoList(\"HW5_data/TrimmedVideos/label/gt_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = pd.DataFrame.from_dict(train_list)\n",
    "dvalid = pd.DataFrame.from_dict(valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npy file loaded\n"
     ]
    }
   ],
   "source": [
    "vgg16 = Extractor(shape=(120,160,3))\n",
    "vgg16.build(vgg16_npy_path=\"../hw3/keras-vgg16.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3235\r"
     ]
    }
   ],
   "source": [
    "features = list()\n",
    "for i in range(dtrain.shape[0]):\n",
    "    print(i, end=\"\\r\")\n",
    "    video = readShortVideo(video_path=train_video_path,\n",
    "                           video_category=dtrain.iloc[i]['Video_category'],\n",
    "                           video_name=dtrain.iloc[i]['Video_name'],\n",
    "                           downsample_factor=12,\n",
    "                           rescale_factor=0.5)\n",
    "    features.append(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29751, 120, 160, 3)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3235\r"
     ]
    }
   ],
   "source": [
    "codes = list()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    for i in range(len(features)):\n",
    "        print(i, end='\\r')\n",
    "        tmp = sess.run(vgg16.output, feed_dict={vgg16.x:features[i]})\n",
    "        codes.append(tmp)\n",
    "\n",
    "with open('codes.pkl', 'wb') as f:\n",
    "    pickle.dump(codes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pickle.load( open( \"codes.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "for i in range(len(codes)):\n",
    "    X.append(np.mean(codes[i], axis=0))\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3236, 10240)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(d.Action_labels).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = one_hot_encoding(Y, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
