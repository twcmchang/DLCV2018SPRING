{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from VGG16_GAP import VGG16_GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as imageio\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progress.bar import Bar\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('save/label_dict.pkl', 'rb') as f:\n",
    "    y_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('save/inv_label_dict.pkl', 'rb') as f:\n",
    "    inv_y_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = \"/home/cmchang/DLCV2018SPRING/final/dlcv_final_2_dataset/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list()\n",
    "for root, subdir, files in os.walk(TEST_DIR):\n",
    "    for file in sorted(files):\n",
    "        if '.jpg' in file:\n",
    "            test_list.append(os.path.join(TEST_DIR, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImgList(file_list):\n",
    "    images = list()\n",
    "    for i, file in enumerate(file_list):\n",
    "        print(i, end=\"\\r\")\n",
    "        img = imageio.imread(file)\n",
    "        img = img.astype(int)\n",
    "        images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformLabel(id_list, y_dict):\n",
    "    label = list()\n",
    "    for uid in list(id_list):\n",
    "        label.append(y_dict[uid])\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(class_numbers, num_classes):\n",
    "    return np.eye(num_classes, dtype=float)[class_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v,f) in zip(global_vars, is_not_initialized) if not f]\n",
    "    if len(not_initialized_vars): \n",
    "            sess.run(tf.variables_initializer(not_initialized_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = readImgList(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_name = \"Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16_GAP(scope_name=scope_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(vgg16_npy_path= para_dict16,#init_model,\n",
    "            shape=Xtest.shape[1:],\n",
    "            classes=len(y_dict),\n",
    "            conv_pre_training=True,\n",
    "            fc_pre_training=True,\n",
    "            new_bn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = [1.0]\n",
    "model.set_idp_operation(dp=dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_number_params(para_dict):\n",
    "    n = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'conv' in k or 'fc' in k:\n",
    "            n += get_params_shape(v[0].shape.as_list())\n",
    "            n += get_params_shape(v[1].shape.as_list())\n",
    "    return n\n",
    "\n",
    "def get_params_shape(shape):\n",
    "    n = 1\n",
    "    for dim in shape:\n",
    "        n = n*dim\n",
    "    return n\n",
    "\n",
    "def count_flops(para_dict, net_shape, input_shape=(3, 218, 178)):\n",
    "    # Format:(channels, rows,cols)\n",
    "    total_flops_per_layer = 0\n",
    "    input_count = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'fc' in k:\n",
    "            continue\n",
    "        elif 'conv' in k:\n",
    "            conv_filter = v[0].shape.as_list()[3::-1] # (64 ,3 ,3 ,3)  # Format: (num_filters, channels, rows, cols)\n",
    "            stride = 1\n",
    "            padding = 1\n",
    "\n",
    "            if conv_filter[1] == 0:\n",
    "                n = conv_filter[2] * conv_filter[3] # vector_length\n",
    "            else:\n",
    "                n = conv_filter[1] * conv_filter[2] * conv_filter[3]  # vector_length\n",
    "\n",
    "            flops_per_instance = n + ( n -1)    # general defination for number of flops (n: multiplications and n-1: additions)\n",
    "\n",
    "            num_instances_per_filter = (( input_shape[1] - conv_filter[2] + 2 * padding) / stride) + 1  # for rows\n",
    "            num_instances_per_filter *= ((input_shape[2] - conv_filter[3] + 2 * padding) / stride) + 1  # multiplying with cols\n",
    "\n",
    "            flops_per_filter = num_instances_per_filter * flops_per_instance\n",
    "            total_flops_per_layer += flops_per_filter * conv_filter[0]  # multiply with number of filters\n",
    "\n",
    "            total_flops_per_layer += conv_filter[0] * input_shape[1] * input_shape[2] # bias\n",
    "\n",
    "            input_shape = net_shape[input_count].as_list()[3:0:-1]\n",
    "            input_count +=1\n",
    "\n",
    "    total_flops_per_layer += net_shape[-1].as_list()[1] *2360*2\n",
    "    return total_flops_per_layer\n",
    "\n",
    "def countFlopsParas(net):\n",
    "    total_flops = count_flops(net.para_dict, net.net_shape)\n",
    "    if total_flops / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_flops/ 1e9 ,'{}'.format('GFlops'))\n",
    "    else:\n",
    "        print(total_flops / 1e6 ,'{}'.format('MFlops'))\n",
    "\n",
    "    total_params = count_number_params(net.para_dict)\n",
    "\n",
    "    if total_params / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_params/ 1e9 ,'{}'.format('G'))\n",
    "    else:\n",
    "        print(total_params / 1e6 ,'{}'.format('M'))\n",
    "    \n",
    "    return total_flops, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops, params = countFlopsParas(model)\n",
    "print(\"Flops: %3f M, Paras: %3f M\" % (flops/1e6, params/1e6))\n",
    "FLAG_flops_M = flops/1e6\n",
    "FLAG_params_M = params/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops, params = countFlopsParas(model)\n",
    "print(\"Flops: %3f M, Paras: %3f M\" % (flops/1e6, params/1e6))\n",
    "FLAG_flops_M = flops/1e6\n",
    "FLAG_params_M = params/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.global_variables())\n",
    "    print(\"Initialized\")\n",
    "    output = []\n",
    "    for dp_i in dp:\n",
    "        for i in range(int(Xtest.shape[0]/200+1)):\n",
    "            print(i, end=\"\\r\")\n",
    "            st = i*200\n",
    "            ed = min((i+1)*200, Xtest.shape[0])\n",
    "            prob = sess.run(model.prob_dict[str(int(dp_i*100))], feed_dict={model.x: Xtest[st:ed,:], \n",
    "                                                                        model.is_train: False})\n",
    "            output.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = np.concatenate(output)\n",
    "pred_class = np.argmax(pred_prob, 1)\n",
    "final_id = list()\n",
    "for pred in pred_class:\n",
    "    final_id.append(inv_y_dict[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doutput = pd.DataFrame({'id':np.arange(len(final_id))+1,\n",
    "              'ans':final_id}, columns=['id','ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doutput.to_csv(\"pred_val8647_final_newCL_v5_lambda-1e-1_dynamic_gap_L5_v3_rescale0-1_save_linear.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"/home/cmchang/DLCV2018SPRING/final/finetune_gap_v3_rescale0-1_save_linear/sparse_dict.npy\", encoding='latin1').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = list()\n",
    "for k, v in sorted(a.items()):\n",
    "    if 'gamma' in k:\n",
    "        mystr = k+',\"'\n",
    "        for i in a[k]:\n",
    "            mystr = mystr+str(i)+\",\"\n",
    "        mystr = mystr+'\"'\n",
    "        # print(mystr)\n",
    "        gamma.append(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(len(a['conv1_1_gamma'])), a['conv1_1_gamma'], label=\"conv1\")\n",
    "plt.plot(range(len(a['conv2_1_gamma'])), a['conv2_1_gamma'], label=\"conv2\")\n",
    "plt.plot(range(len(a['conv3_1_gamma'])), a['conv3_1_gamma'], label=\"conv3\")\n",
    "plt.plot(range(len(a['conv4_1_gamma'])), a['conv4_1_gamma'], label=\"conv4\")\n",
    "plt.plot(range(len(a['conv5_1_gamma'])), a['conv5_1_gamma'], label=\"conv5\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(FLAG_save_dir, \"gamma.csv\"),'a') as resultFile:\n",
    "    wr = csv.writer(resultFile)\n",
    "    wr.writerow(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Check performance on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"/home/cmchang/DLCV2018SPRING/final/\"\n",
    "VALID_DIR = HOME_DIR+\"dlcv_final_2_dataset/val/\"\n",
    "\n",
    "dvalid = pd.read_csv(HOME_DIR+\"dlcv_final_2_dataset/val_id.txt\", header=None,sep=\" \", names=[\"img\", \"id\"])\n",
    "\n",
    "valid_list = list(VALID_DIR+dvalid.img)\n",
    "Xvalid = readImgList(valid_list)\n",
    "\n",
    "yvalid = transformLabel(list(dvalid.id), y_dict)\n",
    "Yvalid = one_hot_encoding(yvalid, len(y_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "with tf.Session() as sess:\n",
    "    with tf.variable_scope(name_or_scope=scope_name) as scop:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "         # validation\n",
    "        val_accu = 0\n",
    "        for i in range(int(Xvalid.shape[0]/batch_size)):\n",
    "            print(i, end='\\r')\n",
    "            st = i*batch_size\n",
    "            ed = (i+1)*batch_size\n",
    "            accu = sess.run(model.accu_dict['100'],\n",
    "                                feed_dict={model.x: Xvalid[st:ed,:],\n",
    "                                            model.y: Yvalid[st:ed,:],\n",
    "                                            model.is_train: False})\n",
    "            val_accu += accu\n",
    "        val_accu = val_accu/int(Xvalid.shape[0]/batch_size)\n",
    "        print(\"val accu : %.4f\" % ( val_accu))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GammaSparsify testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_save_dir = \"/home/cmchang/DLCV2018SPRING/final/finetune_gap_v3_rescale0-1_save_linear/\"\n",
    "a = np.load(FLAG_save_dir+\"para_dict.npy\", encoding=\"latin1\").item()\n",
    "th = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gammaSparsifyVGG16(para_dict, thresh=0.5):\n",
    "    last = None\n",
    "    sparse_dict = {}\n",
    "    N_total, N_remain = 0., 0.\n",
    "    for k, v in sorted(para_dict.items()):\n",
    "        if 'gamma' in k:\n",
    "            # trim networks based on gamma\n",
    "            gamma = v                      \n",
    "            this = np.where(np.abs(gamma) > thresh)[0]\n",
    "            sparse_dict[k] = gamma[this] \n",
    "            \n",
    "            # get the layer name\n",
    "            key = str.split(k,'_gamma')[0]\n",
    "            \n",
    "            # trim conv\n",
    "            conv_, bias_ = para_dict[key]\n",
    "            conv_ = conv_[:,:,:,this]\n",
    "            if last is not None:\n",
    "                conv_ = conv_[:,:,last,:]\n",
    "            bias_ = bias_[this]\n",
    "            sparse_dict[key] = [conv_, bias_]\n",
    "            \n",
    "            # get corresponding beta, bn_mean, bn_variance\n",
    "            sparse_dict[key+\"_beta\"] = para_dict[key+\"_beta\"][this]\n",
    "            sparse_dict[key+\"_bn_mean\"] = para_dict[key+\"_bn_mean\"][this]\n",
    "            sparse_dict[key+\"_bn_variance\"] = para_dict[key+\"_bn_variance\"][this]\n",
    "            \n",
    "            # update\n",
    "            last = this\n",
    "            print('%s from %s to %s : %s ' % (k, len(gamma), len(this), len(this)/len(gamma)))\n",
    "            N_total += len(gamma)\n",
    "            N_remain += len(this)\n",
    "    print('sparsify %s percentage' % (N_remain/N_total))\n",
    "    W_, b_ = para_dict['fc_2']\n",
    "    W_ = W_[last,:]\n",
    "    sparse_dict['fc_2'] = [W_, b_]\n",
    "    return sparse_dict, N_remain/N_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, r = gammaSparsifyVGG16(para_dict=a, thresh=th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(FLAG_save_dir, \"sparse_dict_\"+str(th)+\".npy\"), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
