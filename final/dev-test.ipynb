{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from VGG16_GAP import VGG16_GAP\n",
    "from VGG16_flatten import VGG16_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as imageio\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progress.bar import Bar\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('save/label_dict.pkl', 'rb') as f:\n",
    "    y_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('save/inv_label_dict.pkl', 'rb') as f:\n",
    "    inv_y_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = \"/home/cmchang/DLCV2018SPRING/final/dlcv_final_2_dataset/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list()\n",
    "for root, subdir, files in os.walk(TEST_DIR):\n",
    "    for file in sorted(files):\n",
    "        if '.jpg' in file:\n",
    "            test_list.append(os.path.join(TEST_DIR, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImgList(file_list):\n",
    "    images = list()\n",
    "    for i, file in enumerate(file_list):\n",
    "        print(i, end=\"\\r\")\n",
    "        img = imageio.imread(file)\n",
    "        img = img.astype(int)\n",
    "        images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformLabel(id_list, y_dict):\n",
    "    label = list()\n",
    "    for uid in list(id_list):\n",
    "        label.append(y_dict[uid])\n",
    "    return np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(class_numbers, num_classes):\n",
    "    return np.eye(num_classes, dtype=float)[class_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized(sess):\n",
    "    global_vars = tf.global_variables()\n",
    "    is_not_initialized = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v,f) in zip(global_vars, is_not_initialized) if not f]\n",
    "    if len(not_initialized_vars): \n",
    "            sess.run(tf.variables_initializer(not_initialized_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7151\r"
     ]
    }
   ],
   "source": [
    "Xtest = readImgList(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope_name = \"Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16_GAP(scope_name=scope_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_save_dir = \"/home/cmchang/DLCV2018SPRING/final/CL_v3-cont_dynamic_gap_L5_v3_rescale0-1_save_linear/\"\n",
    "FLAG_init_from = FLAG_save_dir + \"para_dict.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build model started\n",
      "npy file loaded\n",
      "build model finished: 0s\n"
     ]
    }
   ],
   "source": [
    "model.build(vgg16_npy_path=FLAG_init_from,\n",
    "            shape=Xtest.shape[1:],\n",
    "            classes=len(y_dict),\n",
    "            conv_pre_training=True,\n",
    "            fc_pre_training=True,\n",
    "            new_bn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP under test: [1.]\n",
      "[None, 218, 178, 3]\n",
      "[None, 218, 178, 32]\n",
      "AFTER [None, 218, 178, 32]\n",
      "[None, 109, 89, 47]\n",
      "AFTER [None, 109, 89, 47]\n",
      "[None, 109, 89, 63]\n",
      "AFTER [None, 109, 89, 63]\n",
      "[None, 55, 45, 98]\n",
      "AFTER [None, 55, 45, 98]\n",
      "[None, 55, 45, 134]\n",
      "AFTER [None, 55, 45, 134]\n",
      "[None, 55, 45, 147]\n",
      "AFTER [None, 55, 45, 147]\n",
      "[None, 28, 23, 153]\n",
      "AFTER [None, 28, 23, 153]\n",
      "[None, 28, 23, 209]\n",
      "AFTER [None, 28, 23, 209]\n",
      "[None, 28, 23, 181]\n",
      "AFTER [None, 28, 23, 181]\n",
      "[None, 14, 12, 177]\n",
      "AFTER [None, 14, 12, 177]\n",
      "[None, 14, 12, 180]\n",
      "AFTER [None, 14, 12, 180]\n",
      "[None, 14, 12, 230]\n",
      "AFTER [None, 14, 12, 230]\n",
      "Set dp operations finished: 0s\n"
     ]
    }
   ],
   "source": [
    "dp = [1.0]\n",
    "model.set_idp_operation(dp=dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_number_params(para_dict):\n",
    "    n = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'conv' in k or 'fc' in k:\n",
    "            n += get_params_shape(v[0].shape.as_list())\n",
    "            n += get_params_shape(v[1].shape.as_list())\n",
    "    return n\n",
    "\n",
    "def get_params_shape(shape):\n",
    "    n = 1\n",
    "    for dim in shape:\n",
    "        n = n*dim\n",
    "    return n\n",
    "\n",
    "def count_flops(para_dict, net_shape):\n",
    "    input_shape = (3 ,32 ,32) # Format:(channels, rows,cols)\n",
    "    total_flops_per_layer = 0\n",
    "    input_count = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'fc' in k:\n",
    "            continue\n",
    "        elif 'conv' in k:\n",
    "            conv_filter = v[0].shape.as_list()[3::-1] # (64 ,3 ,3 ,3)  # Format: (num_filters, channels, rows, cols)\n",
    "            stride = 1\n",
    "            padding = 1\n",
    "\n",
    "            if conv_filter[1] == 0:\n",
    "                n = conv_filter[2] * conv_filter[3] # vector_length\n",
    "            else:\n",
    "                n = conv_filter[1] * conv_filter[2] * conv_filter[3]  # vector_length\n",
    "\n",
    "            flops_per_instance = n + ( n -1)    # general defination for number of flops (n: multiplications and n-1: additions)\n",
    "\n",
    "            num_instances_per_filter = (( input_shape[1] - conv_filter[2] + 2 * padding) / stride) + 1  # for rows\n",
    "            num_instances_per_filter *= ((input_shape[1] - conv_filter[2] + 2 * padding) / stride) + 1  # multiplying with cols\n",
    "\n",
    "            flops_per_filter = num_instances_per_filter * flops_per_instance\n",
    "            total_flops_per_layer += flops_per_filter * conv_filter[0]  # multiply with number of filters\n",
    "\n",
    "            total_flops_per_layer += conv_filter[0] * input_shape[1] * input_shape[2]\n",
    "\n",
    "            input_shape = net_shape[input_count].as_list()[3:0:-1]\n",
    "            input_count +=1\n",
    "\n",
    "    total_flops_per_layer += net_shape[-1].as_list()[1] *2360*2\n",
    "    return total_flops_per_layer\n",
    "\n",
    "def countFlopsParas(net):\n",
    "    total_flops = count_flops(net.para_dict, net.net_shape)\n",
    "    if total_flops / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_flops/ 1e9 ,'{}'.format('GFlops'))\n",
    "    else:\n",
    "        print(total_flops / 1e6 ,'{}'.format('MFlops'))\n",
    "\n",
    "    total_params = count_number_params(net.para_dict)\n",
    "\n",
    "    if total_params / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_params/ 1e9 ,'{}'.format('G'))\n",
    "    else:\n",
    "        print(total_params / 1e6 ,'{}'.format('M'))\n",
    "    \n",
    "    return total_flops, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.593132123 GFlops\n",
      "4.048755 M\n",
      "Flops: 5593.132123 M, Paras: 4.048755 M\n"
     ]
    }
   ],
   "source": [
    "flops, params = countFlopsParas(model)\n",
    "print(\"Flops: %3f M, Paras: %3f M\" % (flops/1e6, params/1e6))\n",
    "FLAG_flops_M = flops/1e6\n",
    "FLAG_params_M = params/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.593132123 GFlops\n",
      "4.048755 M\n",
      "Flops: 5593.132123 M, Paras: 4.048755 M\n"
     ]
    }
   ],
   "source": [
    "flops, params = countFlopsParas(model)\n",
    "print(\"Flops: %3f M, Paras: %3f M\" % (flops/1e6, params/1e6))\n",
    "FLAG_flops_M = flops/1e6\n",
    "FLAG_params_M = params/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "35\r"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.global_variables())\n",
    "    print(\"Initialized\")\n",
    "    output = []\n",
    "    for dp_i in dp:\n",
    "        for i in range(int(Xtest.shape[0]/200+1)):\n",
    "            print(i, end=\"\\r\")\n",
    "            st = i*200\n",
    "            ed = min((i+1)*200, Xtest.shape[0])\n",
    "            prob = sess.run(model.prob_dict[str(int(dp_i*100))], feed_dict={model.x: Xtest[st:ed,:], \n",
    "                                                                        model.is_train: False})\n",
    "            output.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = np.concatenate(output)\n",
    "pred_class = np.argmax(pred_prob, 1)\n",
    "final_id = list()\n",
    "for pred in pred_class:\n",
    "    final_id.append(inv_y_dict[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "doutput = pd.DataFrame({'id':np.arange(len(final_id))+1,\n",
    "              'ans':final_id}, columns=['id','ans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doutput.to_csv(\"pred_val81_CL_v3-cont_dynamic_gap_L5_v3_rescale0-1_save_linear.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"/home/cmchang/DLCV2018SPRING/final/\"\n",
    "VALID_DIR = HOME_DIR+\"dlcv_final_2_dataset/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvalid = pd.read_csv(HOME_DIR+\"dlcv_final_2_dataset/val_id.txt\", header=None,sep=\" \", names=[\"img\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_list = list(VALID_DIR+dvalid.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvalid = readImgList(valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvalid = transformLabel(list(dvalid.id), y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yvalid = one_hot_encoding(yvalid, len(y_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "with tf.Session() as sess:\n",
    "    with tf.variable_scope(name_or_scope=scope_name) as scop:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "         # validation\n",
    "        val_accu = 0\n",
    "        for i in range(int(Xvalid.shape[0]/batch_size)):\n",
    "            print(i, end='\\r')\n",
    "            st = i*batch_size\n",
    "            ed = (i+1)*batch_size\n",
    "            accu = sess.run(model.accu_dict['100'],\n",
    "                                feed_dict={model.x: Xvalid[st:ed,:],\n",
    "                                            model.y: Yvalid[st:ed,:],\n",
    "                                            model.is_train: False})\n",
    "            val_accu += accu\n",
    "        val_accu = val_accu/int(Xvalid.shape[0]/batch_size)\n",
    "        print(\"val accu : %.4f\" % ( val_accu))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load utils.py\n",
    "from PIL import Image\n",
    "import os\n",
    "import errno\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def gammaSparsifyVGG16(para_dict, thresh=0.5):\n",
    "    last = None\n",
    "    sparse_dict = {}\n",
    "    N_total, N_remain = 0., 0.\n",
    "    for k, v in sorted(para_dict.items()):\n",
    "        if 'gamma' in k:\n",
    "            # trim networks based on gamma\n",
    "            gamma = v                      \n",
    "            this = np.where(np.abs(gamma) > thresh)[0]\n",
    "            sparse_dict[k] = gamma[this] \n",
    "            \n",
    "            # get the layer name\n",
    "            key = str.split(k,'_gamma')[0]\n",
    "            \n",
    "            # trim conv\n",
    "            conv_, bias_ = para_dict[key]\n",
    "            conv_ = conv_[:,:,:,this]\n",
    "            if last is not None:\n",
    "                conv_ = conv_[:,:,last,:]\n",
    "            bias_ = bias_[this]\n",
    "            sparse_dict[key] = [conv_, bias_]\n",
    "            \n",
    "            # get corresponding beta, bn_mean, bn_variance\n",
    "            sparse_dict[key+\"_beta\"] = para_dict[key+\"_beta\"][this]\n",
    "            sparse_dict[key+\"_bn_mean\"] = para_dict[key+\"_bn_mean\"][this]\n",
    "            sparse_dict[key+\"_bn_variance\"] = para_dict[key+\"_bn_variance\"][this]\n",
    "            \n",
    "            # update\n",
    "            last = this\n",
    "            print('%s from %s to %s : %s ' % (k, len(gamma), len(this), len(this)/len(gamma)))\n",
    "            N_total += len(gamma)\n",
    "            N_remain += len(this)\n",
    "    print('sparsify %s percentage' % (N_remain/N_total))\n",
    "    \n",
    "    W_ = para_dict['fc_2'][0][last,:] # np.concatenate([42*i+np.arange(42) for i in list(last)])\n",
    "    b_ = para_dict['fc_2'][1]\n",
    "    \n",
    "    sparse_dict['fc_2'] = [W_, b_]\n",
    "    return sparse_dict, N_remain/N_total\n",
    "\n",
    "def dpSparsifyVGG16(para_dict, dp):\n",
    "    \"\"\"\n",
    "    dp: usage percentage of channels in each layer\n",
    "    \"\"\"\n",
    "    # new_dict = {}\n",
    "    # first = True\n",
    "    # for k,v in sorted(para_dict.items()):\n",
    "    #     if 'conv1_1_' in k:\n",
    "    #         new_dict[k] = v\n",
    "    #     elif 'bn_mean' in k:\n",
    "    #         new_dict[k] = v[:int(len(v)*dp)]\n",
    "    #     elif 'bn_variance' in k:\n",
    "    #         new_dict[k] = v[:int(len(v)*dp)]\n",
    "    #     elif 'gamma' in k:\n",
    "    #         new_dict[k] = v[:int(len(v)*dp)]\n",
    "    #     elif 'beta' in k:\n",
    "    #         new_dict[k] = v[:int(len(v)*dp)]\n",
    "    #     elif 'fc_1' in k:\n",
    "    #         O = v[0].shape[0]\n",
    "    #         new_dict[k] = [v[0][:int(O*dp),:], v[1]]\n",
    "    #     elif 'conv' in k:\n",
    "    #         O = v[0].shape[3]\n",
    "    #         if first:\n",
    "    #             new_dict[k] = v[0][:,:,:,:], v[1][:] #int(O*dp)\n",
    "    #             first = False\n",
    "    #             last = O\n",
    "    #         else:\n",
    "    #             new_dict[k] = v[0][:,:,:last,:int(O*dp)], v[1][:int(O*dp)]\n",
    "    #             last = int(O*dp)\n",
    "    #     else:\n",
    "    #         new_dict[k] = v\n",
    "    #         continue\n",
    "    # return new_dict\n",
    "    first = True\n",
    "    new_dict = {}\n",
    "    last = 3\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            new_dict[k] = v[:int(len(v)*dp)]\n",
    "            print(\"%s:%s\" % (k, new_dict[k].shape))\n",
    "        elif 'bn_variance' in k:\n",
    "            new_dict[k] = v[:int(len(v)*dp)]\n",
    "            print(\"%s:%s\" % (k, new_dict[k].shape))\n",
    "        elif 'gamma' in k:\n",
    "            new_dict[k] = v[:int(len(v)*dp)]\n",
    "            print(\"%s:%s\" % (k, new_dict[k].shape))\n",
    "        elif 'beta' in k:\n",
    "            new_dict[k] = v[:int(len(v)*dp)]\n",
    "            print(\"%s:%s\" % (k, new_dict[k].shape))\n",
    "        elif 'fc_2' in k:\n",
    "            O = v[0].shape[0]\n",
    "            new_dict[k] = [v[0][:int(O*dp),:], v[1]]\n",
    "        elif 'conv' in k:\n",
    "            O = v[0].shape[3]\n",
    "            new_dict[k] = v[0][:,:,:last,:int(O*dp)], v[1][:int(O*dp)]\n",
    "            # if first:\n",
    "            #     first = False\n",
    "            #     last = O\n",
    "            # else:\n",
    "            last = int(O*dp)\n",
    "            print(\"W%s:%s\" % (k, new_dict[k][0].shape))\n",
    "            print(\"b%s:%s\" % (k, new_dict[k][1].shape))\n",
    "        else:\n",
    "            new_dict[k] = v\n",
    "    return new_dict\n",
    "\n",
    "def count_number_params(para_dict):\n",
    "    n = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'conv' in k or 'fc' in k:\n",
    "            n += get_params_shape(list(v[0].shape))\n",
    "            n += get_params_shape(list(v[1].shape))\n",
    "    return n\n",
    "\n",
    "def get_params_shape(shape):\n",
    "    n = 1\n",
    "    for dim in shape:\n",
    "        n = n*dim\n",
    "    return n\n",
    "\n",
    "def count_flops(para_dict, net_shape):\n",
    "    input_shape = (3 ,32 ,32) # Format:(channels, rows,cols)\n",
    "    total_flops_per_layer = 0\n",
    "    input_count = 0\n",
    "    for k,v in sorted(para_dict.items()):\n",
    "        if 'bn_mean' in k:\n",
    "            continue\n",
    "        elif 'bn_variance' in k:\n",
    "            continue\n",
    "        elif 'gamma' in k:\n",
    "            continue\n",
    "        elif 'beta' in k:\n",
    "            continue\n",
    "        elif 'fc' in k:\n",
    "            continue\n",
    "        elif 'conv' in k:\n",
    "            conv_filter = v[0].shape.as_list()[3::-1] # (64 ,3 ,3 ,3)  # Format: (num_filters, channels, rows, cols)\n",
    "            stride = 1\n",
    "            padding = 1\n",
    "\n",
    "            if conv_filter[1] == 0:\n",
    "                n = conv_filter[2] * conv_filter[3] # vector_length\n",
    "            else:\n",
    "                n = conv_filter[1] * conv_filter[2] * conv_filter[3]  # vector_length\n",
    "\n",
    "            flops_per_instance = n + ( n -1)    # general defination for number of flops (n: multiplications and n-1: additions)\n",
    "\n",
    "            num_instances_per_filter = (( input_shape[1] - conv_filter[2] + 2 * padding) / stride) + 1  # for rows\n",
    "            num_instances_per_filter *= ((input_shape[1] - conv_filter[2] + 2 * padding) / stride) + 1  # multiplying with cols\n",
    "\n",
    "            flops_per_filter = num_instances_per_filter * flops_per_instance\n",
    "            total_flops_per_layer += flops_per_filter * conv_filter[0]  # multiply with number of filters\n",
    "\n",
    "            total_flops_per_layer += conv_filter[0] * input_shape[1] * input_shape[2]\n",
    "\n",
    "            input_shape = net_shape[input_count].as_list()[3:0:-1]\n",
    "            input_count +=1\n",
    "\n",
    "    total_flops_per_layer += net_shape[-1].as_list()[3] * 512 *2 + 512*10*2\n",
    "    return total_flops_per_layer\n",
    "\n",
    "def countFlopsParas(net):\n",
    "    total_flops = count_flops(net.para_dict, net.net_shape)\n",
    "    if total_flops / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_flops/ 1e9 ,'{}'.format('GFlops'))\n",
    "    else:\n",
    "        print(total_flops / 1e6 ,'{}'.format('MFlops'))\n",
    "\n",
    "    total_params = count_number_params(net.para_dict)\n",
    "\n",
    "    if total_params / 1e9 > 1:   # for Giga Flops\n",
    "        print(total_params/ 1e9 ,'{}'.format('G'))\n",
    "    else:\n",
    "        print(total_params / 1e6 ,'{}'.format('M'))\n",
    "    \n",
    "    return total_flops, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpSparsifyVGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_save_dir = \"/home/cmchang/DLCV2018SPRING/final/dynamic_gap_L5_v3_rescale0-1_save_linear/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(FLAG_save_dir+\"para_dict.npy\", encoding=\"latin1\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dpSparsifyVGG16(a, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(len(a['conv1_1_gamma'])), a['conv1_1_gamma'], label=\"conv1\")\n",
    "# plt.plot(range(len(a['conv2_1_gamma'])), a['conv2_1_gamma'], label=\"conv2\")\n",
    "# plt.plot(range(len(a['conv3_1_gamma'])), a['conv3_1_gamma'], label=\"conv3\")\n",
    "# plt.plot(range(len(a['conv4_1_gamma'])), a['conv4_1_gamma'], label=\"conv4\")\n",
    "# plt.plot(range(len(a['conv5_1_gamma'])), a['conv5_2_gamma'], label=\"conv5\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 8e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, r = gammaSparsifyVGG16(para_dict=a, thresh=th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(FLAG_save_dir, \"sparse_dict_\"+str(th)+\".npy\"), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
